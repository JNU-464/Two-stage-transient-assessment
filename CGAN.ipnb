# 加载临界样本数据
data_path = 'C:\\Users\\camby\\Desktop\\linjie8_original.xlsx'
data = pd.read_excel(data_path)

# 分离特征和标签
X_data = data.drop(columns=['label']).values  # 特征
y_data = data['label'].values                 # 标签

# 将标签转换为整数类型
y_data = y_data.astype(int)

# 特征缩放（使用 MinMaxScaler 将特征缩放到 [0, 1] 范围）
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X_data)

# 获取特征维度和类别数量
input_dim = X_scaled.shape[1]
num_classes = len(np.unique(y_data))

# 构建生成器和判别器
def build_generator(noise_dim, input_dim, num_classes):
    noise_input = Input(shape=(noise_dim,))
    label_input = Input(shape=(1,), dtype='int32')
    label_embedding = Embedding(num_classes, noise_dim)(label_input)
    label_embedding = Flatten()(label_embedding)
    model_input = multiply([noise_input, label_embedding])
    
    x = Dense(256)(model_input)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Dense(512)(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Dense(1024)(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Dense(input_dim, activation='sigmoid')(x)
    
    generator = Model([noise_input, label_input], x)
    return generator

def build_discriminator(input_dim, num_classes):
    data_input = Input(shape=(input_dim,))
    label_input = Input(shape=(1,), dtype='int32')
    label_embedding = Embedding(num_classes, input_dim)(label_input)
    label_embedding = Flatten()(label_embedding)
    model_input = multiply([data_input, label_embedding])
    
    x = Dense(512)(model_input)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dense(512)(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dense(256)(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dense(1, activation='sigmoid')(x)
    
    discriminator = Model([data_input, label_input], x)
    return discriminator

# 设置CGAN参数
noise_dim = 100  # 噪声维度

# 构建生成器和判别器
generator = build_generator(noise_dim, input_dim, num_classes)
discriminator = build_discriminator(input_dim, num_classes)

# 编译判别器
discriminator.compile(optimizer=optimizers.Adam(0.0001, 0.5),
                      loss='binary_crossentropy',
                      metrics=['accuracy'])

# 在训练生成器时，冻结判别器的权重
discriminator.trainable = False

# 构建CGAN模型
noise_input = Input(shape=(noise_dim,))
label_input = Input(shape=(1,), dtype='int32')
generated_data = generator([noise_input, label_input])
validity = discriminator([generated_data, label_input])

cgan = Model([noise_input, label_input], validity)
cgan.compile(optimizer=optimizers.Adam(0.0001, 0.5),
             loss='binary_crossentropy')

# 定义训练参数
epochs = 10000
batch_size = 32
sample_interval = 100

# 准备标签用于训练
valid = np.ones((batch_size, 1))
fake = np.zeros((batch_size, 1))

# 用于保存损失值
d_losses = []
g_losses = []

# 开始训练
for epoch in range(epochs + 1):

    # ---------------------
    #  训练判别器
    # ---------------------
    # 从真实数据中采样
    idx = np.random.randint(0, X_scaled.shape[0], batch_size)
    real_data = X_scaled[idx]
    labels = y_data[idx]

    # 生成噪声和生成数据
    noise = np.random.normal(0, 1, (batch_size, noise_dim))
    gen_data = generator.predict([noise, labels])

    # 训练判别器
    d_loss_real = discriminator.train_on_batch([real_data, labels], valid)
    d_loss_fake = discriminator.train_on_batch([gen_data, labels], fake)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # ---------------------
    #  训练生成器
    # ---------------------
    sampled_labels = np.random.randint(0, num_classes, batch_size)
    g_loss = cgan.train_on_batch([noise, sampled_labels], valid)

    # 保存损失值
    d_losses.append(d_loss[0])
    g_losses.append(g_loss)

    # 打印损失
    if epoch % sample_interval == 0:
        print(f"{epoch} [D loss: {d_loss[0]:.4f}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]")

# 绘制损失曲线
plt.figure(figsize=(10, 5))
plt.plot(d_losses, label='Discriminator Loss')
plt.plot(g_losses, label='Generator Loss')
plt.title('Loss during Training')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.legend()
plt.show()

# 生成指定数量的新样本
def generate_samples(generator, num_samples, noise_dim, num_classes):
    noise = np.random.normal(0, 1, (num_samples, noise_dim))
    sampled_labels = np.random.randint(0, num_classes, num_samples)
    gen_data = generator.predict([noise, sampled_labels])
    return gen_data, sampled_labels

# 生成 2000 个新样本
num_new_samples = 2000
gen_data_scaled, gen_labels = generate_samples(generator, num_new_samples, noise_dim, num_classes)

# 反归一化生成的数据
gen_data = scaler.inverse_transform(gen_data_scaled)

# 将生成的数据转换为 DataFrame
gen_df = pd.DataFrame(gen_data, columns=data.columns[:-1])
gen_df['label'] = gen_labels

# 保存生成的样本到Excel文件
output_path = 'C:\\Users\\camby\\Desktop\\CGAN_generated_samples_adjusted.xlsx'
gen_df.to_excel(output_path, index=False)
print(f"Generated samples saved to {output_path}")

# 获取生成的样本并将其加入增强样本集中
X_generated = gen_df.drop(columns=['label']).values
y_generated = gen_df['label'].values

# 增强样本集
X_enhanced = np.concatenate([X_data, X_generated], axis=0)
y_enhanced = np.concatenate([y_data, y_generated], axis=0)

# 输出增强样本集到Excel
output_df = pd.DataFrame(X_enhanced, columns=[f'feature_{i+1}' for i in range(X_enhanced.shape[1])])
output_df['label'] = y_enhanced
output_path = 'C:\\Users\\camby\\Desktop\\yangben8.xlsx'
output_df.to_excel(output_path, index=False)
print(f"Samples saved to {output_path}")
